broker {
   pipeline.class = org.cg.spark.databroker.example.TweetsSparkPipeline
   bootstrap.servers = "192.168.99.1:9092"
   topics = ["tweets"]
   batch.interval = 6000
   cluster.name = "channelServer"

   akka {
     #extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]
     actor.provider = "akka.cluster.ClusterActorRefProvider"
     
     remote.netty.tcp.hostname="jobserver"
     # Production port should be 0
     remote.netty.tcp.port=2929
     

     remote.netty.tcp.bind-hostname="172.17.0.3"
     remote.netty.tcp.bind-port=2929
     cluster {
       seed-nodes = [
         "akka.tcp://channelServer@jobserver:2828", "akka.tcp://channelServer@192.168.99.1:5858"]
       auto-down-unreachable-after = 10s
     }

  }
}

spark.jobserver.job-jar-paths {    # NOTE: you may need an absolute path below
  "org.cg.spark.databroker.example.TweetsSparkBroker" = /app/org.cg.spark-databroker-0.0.1-SNAPSHOT.jar
}


spark.context-settings.dependent-jar-uris = ["file:///app/org.cg.spark-databroker-0.0.1-SNAPSHOT-jar-with-dependencies.jar", "file:///app/akka-cluster_2.10-2.3.11.jar","file:///app/akka-contrib_2.10-2.3.11.jar"]
